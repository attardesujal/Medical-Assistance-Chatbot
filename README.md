ğŸ©º Aarogya â€“ Local Medical Chatbot
Aarogya is an intelligent medical assistant chatbot that runs completely offline using the Mistral 7B model via llama.cpp, with FAISS-based document search and multi-language support. Itâ€™s built with Streamlit, offers markdown-rich responses, and is optimized for GPU acceleration on local machines.

ğŸš€ Features
âœ… Runs entirely offline using a local .gguf Mistral model

âœ… FAISS vector store for fast, context-aware medical retrieval

âœ… ChatGPT-style markdown output (with headings, emojis, bullets)

âœ… Multi-language support via Google Translate

âœ… Streamlit UI with dark theme, logo, sidebar, and chat bubbles

âœ… Custom prompt tuning for precise medical Q&A

 Project Structure
 ğŸ“ local_model
â”‚
â”œâ”€â”€ llama.cpp/                          # llama.cpp repo (used for local LLM)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral/
â”‚       â””â”€â”€ mistral-7b-instruct-v0.1.Q4_K_M.gguf  # Local quantized LLM
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ db_faiss/
â”‚       â”œâ”€â”€ index.faiss                # FAISS index (large, don't upload to GitHub)
â”‚       â””â”€â”€ index.pkl                  # FAISS metadata
â”‚
â”œâ”€â”€ 0.png                              # Sidebar logo
â”œâ”€â”€ 
â””â”€â”€ app.py



